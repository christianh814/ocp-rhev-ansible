# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
etcd
glusterfs

# Set variables common for all OSEv3 hosts
[OSEv3:vars]

# If ansible_ssh_user is not root, ansible_sudo must be set to true
ansible_ssh_user=root
#ansible_sudo=true
#ansible_become=yes

# Install Enterprise or Origin; set up ntp
openshift_deployment_type=openshift-enterprise
openshift_clock_enabled=true
oreg_auth_user="{{ lookup('env','OREG_AUTH_USER') }}"
oreg_auth_password="{{ lookup('env','OREG_AUTH_PASSWORD') }}"

# Network/DNS Related
openshift_master_default_subdomain={{ wildcard_domain }}
osm_cluster_network_cidr=10.1.0.0/16
osm_host_subnet_length=8
openshift_portal_net=172.30.0.0/16
openshift_docker_insecure_registries=172.30.0.0/16

# CNS Storage
openshift_storage_glusterfs_namespace=glusterfs
openshift_storage_glusterfs_name=storage
openshift_storage_glusterfs_heketi_wipe=true
openshift_storage_glusterfs_wipe=true
openshift_storage_glusterfs_storageclass_default=true
openshift_storage_glusterfs_block_storageclass=true
openshift_storage_glusterfs_block_host_vol_size=50
openshift_storage_glusterfs_image=registry.redhat.io/rhgs3/rhgs-server-rhel7:v3.11
openshift_storage_glusterfs_block_image=registry.redhat.io/rhgs3/rhgs-gluster-block-prov-rhel7:v3.11
openshift_storage_glusterfs_s3_image=registry.redhat.io/rhgs3/rhgs-s3-server-rhel7:v3.11
openshift_storage_glusterfs_heketi_image=registry.redhat.io/rhgs3/rhgs-volmanager-rhel7:v3.11

# Automatically Deploy the router
openshift_hosted_manage_router=true
#openshift_router_selector={'node-role.kubernetes.io/infra':'true'}

# Automatically deploy the registry using glusterfs
openshift_hosted_manage_registry=true
openshift_hosted_registry_storage_kind=glusterfs
openshift_hosted_registry_storage_volume_size=25Gi
#openshift_registry_selector={'node-role.kubernetes.io/infra':'true'}
#openshift_hosted_registry_replicas=2

# Disble Checks
openshift_disable_check=disk_availability,docker_storage,memory_availability

# 
# Network Policies that are available:
# redhat/openshift-ovs-networkpolicy # fine grained control
# redhat/openshift-ovs-multitenant # each project gets it's own "private" network
# redhat/openshift-ovs-subnet # "flat" network
#
# Network OVS Plugin to use
os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

# Uncomment when setting up logging/metrics/prometheus
openshift_master_dynamic_provisioning_enabled=true
dynamic_volumes_check=False

# Logging
openshift_logging_install_logging=true
openshift_logging_es_pvc_dynamic=true
openshift_logging_es_pvc_size=20Gi
openshift_logging_es_pvc_storage_class_name=glusterfs-storage-block
openshift_logging_curator_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_logging_es_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_logging_kibana_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_logging_es_memory_limit=4G

# Metrics
openshift_metrics_install_metrics=true
openshift_metrics_cassandra_pvc_size=20Gi
openshift_metrics_cassandra_storage_type=dynamic
openshift_metrics_cassandra_pvc_storage_class_name=glusterfs-storage-block
openshift_metrics_hawkular_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_metrics_heapster_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_metrics_cassandra_nodeselector={'node-role.kubernetes.io/infra':'true'}

# Prometheus Metrics
openshift_cluster_monitoring_operator_install=true
openshift_cluster_monitoring_operator_prometheus_storage_enabled=true
openshift_cluster_monitoring_operator_alertmanager_storage_enabled=true
openshift_cluster_monitoring_operator_prometheus_storage_capacity=10Gi
openshift_cluster_monitoring_operator_alertmanager_storage_capacity=10Gi
openshift_cluster_monitoring_operator_node_selector={'node-role.kubernetes.io/infra':'true'}

## Ansible Service Broker - only install it if you REALLY need it.
ansible_service_broker_install=false

# If using Route53 or you're pointed to the master with a "vanity" name
openshift_master_public_api_url=https://{{ console_fqdn }}:8443
openshift_master_public_console_url=https://{{ console_fqdn }}:8443/console
openshift_master_cluster_public_hostname={{ console_fqdn }}
openshift_master_api_port=8443
openshift_master_console_port=8443

# The following enabled htpasswd authentication
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]
openshift_master_htpasswd_users={'developer': '$apr1$q2fVVf46$85HP/4JHGYeFBKAKPBblo0'}

## OpenShift host groups

# host group for etcd
[etcd]
{% for master in ovirt_vms if master.name.startswith('master') %}
{{ master.fqdn }}
{% endfor %}


# host group for masters - set scedulable to "true" for the web-console pod
[masters]
{% for master in ovirt_vms if master.name.startswith('master') %}
{{ master.fqdn }} openshift_schedulable=true
{% endfor %}


# host group for nodes, includes region info
[nodes]
{% for master in ovirt_vms if master.name.startswith('master') %}
{{ master.fqdn }} openshift_node_group_name='node-config-master-infra'
{% endfor %}
{% for app in ovirt_vms if app.name.startswith('app') %}
{{ app.fqdn }} openshift_node_group_name='node-config-compute'
{% endfor %}

[glusterfs]
# You WILL need to change glusterfs_ip and glusterfs_devices here!!!!
{% for app in ovirt_vms if app.name.startswith('app') %}
{{ app.fqdn }} glusterfs_ip={{ app | ovirtvmipv4 }} glusterfs_zone={{ loop.index }} glusterfs_devices='[ "/dev/sdb" ]'
{% endfor %}

##
##
