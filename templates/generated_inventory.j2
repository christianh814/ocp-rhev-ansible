# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
etcd
#lb
glusterfs

# Set variables common for all OSEv3 hosts
[OSEv3:vars]

# If ansible_ssh_user is not root, ansible_sudo must be set to true
ansible_ssh_user=root
#ansible_sudo=true
#ansible_become=yes

# Install Enterprise or Origin; set up ntp
openshift_deployment_type=openshift-enterprise
openshift_clock_enabled=true
oreg_auth_user="{{ lookup('env','OREG_AUTH_USER') }}"
oreg_auth_password="{{ lookup('env','OREG_AUTH_PASSWORD') }}"

# Network/DNS Related
openshift_master_default_subdomain={{ wildcard_domain }}
osm_cluster_network_cidr=10.1.0.0/16
osm_host_subnet_length=8
openshift_portal_net=172.30.0.0/16
openshift_docker_insecure_registries=172.30.0.0/16

# CNS Storage
openshift_storage_glusterfs_namespace=glusterfs
openshift_storage_glusterfs_name=storage
openshift_storage_glusterfs_heketi_wipe=true
openshift_storage_glusterfs_wipe=true
openshift_storage_glusterfs_storageclass_default=true
openshift_storage_glusterfs_block_storageclass=true
openshift_storage_glusterfs_block_host_vol_size=50
openshift_storage_glusterfs_image=registry.redhat.io/rhgs3/rhgs-server-rhel7:v3.11
openshift_storage_glusterfs_block_image=registry.redhat.io/rhgs3/rhgs-gluster-block-prov-rhel7:v3.11
openshift_storage_glusterfs_s3_image=registry.redhat.io/rhgs3/rhgs-s3-server-rhel7:v3.11
openshift_storage_glusterfs_heketi_image=registry.redhat.io/rhgs3/rhgs-volmanager-rhel7:v3.11

# Automatically Deploy the router
openshift_hosted_manage_router=true
#openshift_router_selector={'node-role.kubernetes.io/infra':'true'}

# Automatically deploy the registry using glusterfs
openshift_hosted_manage_registry=true
openshift_hosted_registry_storage_kind=glusterfs
openshift_hosted_registry_storage_volume_size=25Gi
#openshift_registry_selector={'node-role.kubernetes.io/infra':'true'}
#openshift_hosted_registry_replicas=2

# Disble Checks
openshift_disable_check=disk_availability,docker_storage,memory_availability,docker_image_availability,package_availability,package_version

# 
# Network Policies that are available:
# redhat/openshift-ovs-networkpolicy # fine grained control
# redhat/openshift-ovs-multitenant # each project gets it's own "private" network
# redhat/openshift-ovs-subnet # "flat" network
#
# Network OVS Plugin to use
os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

# Uncomment when setting up logging/metrics/prometheus
openshift_master_dynamic_provisioning_enabled=true
dynamic_volumes_check=False

# Logging
openshift_logging_install_logging=true
openshift_logging_es_pvc_dynamic=true
openshift_logging_es_pvc_size=10Gi
openshift_logging_es_pvc_storage_class_name=glusterfs-storage-block
openshift_logging_curator_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_logging_es_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_logging_kibana_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_logging_es_memory_limit=4G
openshift_logging_es_cluster_size=3

# Metrics
openshift_metrics_install_metrics=true
openshift_metrics_cassandra_pvc_size=10Gi
openshift_metrics_cassandra_storage_type=dynamic
openshift_metrics_cassandra_pvc_storage_class_name=glusterfs-storage-block
openshift_metrics_hawkular_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_metrics_heapster_nodeselector={'node-role.kubernetes.io/infra':'true'}
openshift_metrics_cassandra_nodeselector={'node-role.kubernetes.io/infra':'true'}

# Prometheus Metrics
openshift_cluster_monitoring_operator_install=true
openshift_cluster_monitoring_operator_prometheus_storage_enabled=true
openshift_cluster_monitoring_operator_alertmanager_storage_enabled=true
openshift_cluster_monitoring_operator_prometheus_storage_capacity=10Gi
openshift_cluster_monitoring_operator_alertmanager_storage_capacity=10Gi
openshift_cluster_monitoring_operator_node_selector={'node-role.kubernetes.io/infra':'true'}

## Ansible Service Broker - only install it if you REALLY need it.
ansible_service_broker_install=false

# If using Route53 or you're pointed to the master with a "vanity" name
openshift_master_public_api_url=https://{{ lb_fqdn }}:8443
openshift_master_public_console_url=https://{{ lb_fqdn }}:8443/console
openshift_master_api_port=8443
openshift_master_console_port=8443

# Native high availbility cluster method with optional load balancer.
# If no lb group is defined installer assumes that a load balancer has 
# been preconfigured. For installation the value of
# openshift_master_cluster_hostname must resolve to the load balancer
# or to one or all of the masters defined in the inventory if no load
# balancer is present.
openshift_master_cluster_method=native
openshift_master_cluster_hostname={{ lb_fqdn }}
openshift_master_cluster_public_hostname={{ lb_fqdn }}

# The following enabled htpasswd authentication
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]
openshift_master_htpasswd_users={'developer': '$apr1$q2fVVf46$85HP/4JHGYeFBKAKPBblo0'}

## OpenShift host groups

# host group for etcd
[etcd]
{% for master in ovirt_vms if master.name.startswith('master') %}
{{ master.fqdn }}
{% endfor %}


# host group for loadbalancers - uncomment if you need it; you may need to modify the entry as well
# [lb]
# {{ lb_fqdn }}

# host group for masters - set scedulable to "true" for the web-console pod
[masters]
{% for master in ovirt_vms if master.name.startswith('master') %}
{{ master.fqdn }} openshift_schedulable=true
{% endfor %}


# host group for nodes, includes region info
[nodes]
{% for master in ovirt_vms if master.name.startswith('master') %}
{{ master.fqdn }} openshift_node_group_name='node-config-master'
{% endfor %}
{% for infra in ovirt_vms if infra.name.startswith('infra') %}
{{ infra.fqdn }} openshift_node_group_name='node-config-infra'
{% endfor %}
{% for app in ovirt_vms if app.name.startswith('app') %}
{{ app.fqdn }} openshift_node_group_name='node-config-compute'
{% endfor %}

[glusterfs]
# You WILL need to change glusterfs_ip and glusterfs_devices here!!!!
{% for app in ovirt_vms if app.name.startswith('app') %}
{{ app.fqdn }} glusterfs_ip={{ app | ovirtvmipv4 }} glusterfs_zone={{ loop.index }} glusterfs_devices='[ "/dev/DISK" ]'
{% endfor %}

##
##
